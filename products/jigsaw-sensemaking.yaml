# Jigsaw Sensemaking Tools
# https://github.com/Jigsaw-Code/sensemaking-tools

id: jigsaw-sensemaking
name: Jigsaw Sensemaking Tools
version: "1.0.0"
type: product
url: https://github.com/Jigsaw-Code/sensemaking-tools
tags:
  - sensemaking
  - topic-modeling
  - open-source
  - polis-compatible
  - summarization

source:
  creator: Jigsaw (Google)
  reference_url: https://github.com/Jigsaw-Code/sensemaking-tools
  license: Apache 2.0

description: >
  Open-source tools for analyzing large-scale online conversations using LLMs.
  Takes participant comments with vote data, discovers topics hierarchically,
  categorizes statements, and produces narrative summary reports highlighting
  common ground and differences of opinion. Designed to work with Polis-style data.

agents:
  - id: topic-modeler
    role: Topic Discovery Agent
    type: llm
    model: gemini-1.5-pro
    description: >
      Discovers discussion topics hierarchically from raw comments.
      Produces top-level topics and subtopics. Can also accept
      user-supplied topic definitions.
    responsibilities:
      - Discover topics from comment corpus
      - Build hierarchical topic tree (topics → subtopics)
      - Handle user-supplied topic overrides

  - id: categorizer
    role: Statement Categorizer
    type: llm
    model: gemini-1.5-pro
    description: >
      Assigns each comment to one or more topics in batches.
      Uses Vertex AI's constrained decoding for reliable JSON output.
      Retries failed assignments automatically.
    responsibilities:
      - Categorize comments into discovered topics
      - Handle multi-topic assignment
      - Ensure reliable classification via constrained decoding
      - Retry failed categorizations

  - id: summarizer
    role: Recursive Summarizer
    type: llm
    model: gemini-1.5-pro
    description: >
      Generates multi-section narrative summaries via recursive
      multi-call LLM process. Identifies common ground and
      differences of opinion using vote statistics.
    responsibilities:
      - Generate introduction (statement/vote/topic counts)
      - Write cross-topic overview synthesis
      - Identify top 5 subtopics by traffic
      - Produce per-subtopic sections with common ground and differences
      - Assign relative agreement labels (high to low)

participants:
  input_mode: text  # comments + votes (agree/disagree/pass)
  interaction: large-group
  synchronicity: async
  scale:
    min: 50
    max: 100000
    typical: 1000
  anonymity: true

stages:
  - name: Data Ingestion
    description: Load participant comments with vote data
    agent: topic-modeler
    input:
      - CSV with comment_text, comment-id, agrees, disagrees, passes
      - Optional: group-level breakdowns
    processing: Parse and validate input data
    memory: []
    output:
      - Structured comment corpus with vote counts
    duration: automated
    human_in_loop: false

  - name: Topic Discovery
    description: Discover hierarchical topic structure
    agent: topic-modeler
    input:
      - Comment corpus
    processing: >
      LLM analyzes comments to discover natural topic groupings.
      Builds hierarchical tree of topics and subtopics.
    memory:
      - Full comment corpus
    output:
      - Topic hierarchy (topics → subtopics)
      - Topic labels and descriptions
    duration: automated
    human_in_loop: false

  - name: Comment Categorization
    description: Assign each comment to topics
    agent: categorizer
    input:
      - Comment corpus
      - Topic hierarchy
    processing: >
      Batch-process comments through LLM with constrained decoding
      (Vertex AI JSON schema enforcement). Each comment assigned to
      one or more topics. ~90% run-to-run stability.
    memory:
      - Topic hierarchy
    output:
      - Comments with topic assignments
      - Categorization confidence scores
    duration: "automated (~$1 per 1,000 statements on Gemini 1.5 Pro)"
    human_in_loop: false

  - name: Summary Generation
    description: Produce narrative report with common ground and differences
    agent: summarizer
    input:
      - Categorized comments
      - Vote statistics per statement
    processing: >
      Recursive multi-call summarization. For each subtopic: identify
      themes, compute common ground (from vote stats, not text analysis,
      min 20 votes per statement), label relative agreement level.
    memory:
      - All categorized comments
      - Vote statistics
    output:
      - Narrative summary report (Markdown/HTML)
      - Per-subtopic analysis (themes, common ground, differences)
      - Relative agreement labels
    duration: automated
    human_in_loop: false

data_flow:
  inputs:
    - CSV of comments with vote data (Polis-compatible format)
  outputs:
    - Narrative summary report (Markdown/HTML)
    - Topic-assigned comments (CSV)
    - Full analysis (JSON × 3: topics, alignments, summary)
    - Static web UI (HTML)
  storage:
    - Processed outputs (files)

patterns:
  - cross-pollination  # surfacing common ground and differences

evaluation:
  metrics:
    - Categorization stability (~90% run-to-run)
    - Hallucination rate (manual + automated review)
    - Topic coherence (silhouette coefficient)
    - Common ground accuracy (vs vote statistics)
